# Scarpy-Spider
基于scrapy框架的python网络爬虫


 1.小说网站 32中文网 的所有小说爬取，并保存到mongoDB数据库中。

 2.网站 新浪新闻 的所有分类新闻的爬取，保存到当地磁盘下
 
 3.东莞阳光热线问政平台 的所有投诉爬取，保存在当地磁盘下，保存为json格式文件
   爬取过程中遇到的问题：
   a.早期爬取的时候到四十页，会有反爬，页面url的参数发生变化，需要进行参数更改，后期该反爬没有了。。。
   b.前端部分很混乱，id名字，class名字经常会有变动，而且是偶尔的变动，xpath匹配时经常出错，爬取过程中从反馈日志中也能看到，对匹配规则进行了一定修改，但是治标不治本。



